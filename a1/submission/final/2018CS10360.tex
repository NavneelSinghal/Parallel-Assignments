\documentclass[a4paper]{article}
\usepackage[english]{babel}
\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
% \usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{import}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{xcolor}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{thmtools}
\usepackage{enumitem}
\usepackage[framemethod=TikZ]{mdframed}

\usepackage{xpatch}

\usepackage{boites}
\makeatletter
\xpatchcmd{\endmdframed}
{\aftergroup\endmdf@trivlist\color@endgroup}
{\endmdf@trivlist\color@endgroup\@doendpe}
{}{}
\makeatother

%\usepackage[poster]{tcolorbox}
%\allowdisplaybreaks
%\sloppy

\usepackage[many]{tcolorbox}

\xpatchcmd{\proof}{\itshape}{\bfseries\itshape}{}{}

% to set box separation
\setlength{\fboxsep}{0.8em}
\def\breakboxskip{7pt}
\def\breakboxparindent{0em}

\newenvironment{proof}{\begin{breakbox}\textit{Proof.}}{\hfill$\square$\end{breakbox}}
\newenvironment{ans}{\begin{breakbox}\textit{Answer.}}{\end{breakbox}}
\newenvironment{soln}{\begin{breakbox}\textit{Solution.}}{\end{breakbox}}

% \tcolorboxenvironment{proof}{
%     blanker,
%     before skip=\topsep,
%     after skip=\topsep,
%     borderline={0.4pt}{0.4pt}{black},
%     breakable,
%     left=12pt,
%     right=12pt,
%     top=12pt,
%     bottom=12pt,
% }
% 
% \tcolorboxenvironment{ans}{
%     blanker,
%     before skip=\topsep,
%     after skip=\topsep,
%     borderline={0.4pt}{0.4pt}{black},
%     breakable,
%     left=12pt,
%     right=12pt,
% }

\mdfdefinestyle{enclosed}{
    linecolor=black
    ,backgroundcolor=none
    ,apptotikzsetting={\tikzset{mdfbackground/.append style={fill=gray!100,fill opacity=.3}}}
    ,frametitlefont=\sffamily\bfseries\color{black}
    ,splittopskip=.5cm
    ,frametitlebelowskip=.0cm
    ,topline=true
    ,bottomline=true
    ,rightline=true
    ,leftline=true
    ,leftmargin=0.01cm
    ,linewidth=0.02cm
    ,skipabove=0.01cm
    ,innerbottommargin=0.1cm
    ,skipbelow=0.1cm
}

\mdfsetup{%
    middlelinecolor=black,
    middlelinewidth=1pt,
roundcorner=4pt}

\setlength{\parindent}{0pt}

\mdtheorem[style=enclosed]{theorem}{Theorem}
\mdtheorem[style=enclosed]{lemma}{Lemma}[theorem]
\mdtheorem[style=enclosed]{claim}{Claim}[theorem]
\mdtheorem[style=enclosed]{ques}{Question}
\mdtheorem[style=enclosed]{defn}{Definition}
\mdtheorem[style=enclosed]{notn}{Notation}
\mdtheorem[style=enclosed]{obs}{Observation}
\mdtheorem[style=enclosed]{eg}{Example}
\mdtheorem[style=enclosed]{cor}{Corollary}
\mdtheorem[style=enclosed]{note}{Note}

% \let\thetheorem=\relax
% \let\thelemma=\relax
% \let\theclaim=\relax
% \let\theques=\relax
% \let\thedefn=\relax
% \let\thenotn=\relax
% \let\theobs=\relax
% \let\thecor=\relax
% \let\thenote=\relax

% \renewcommand\qedsymbol{$\blacksquare$}
\newcommand{\nl}{\vspace{0.2cm}\\}
\newcommand{\mc}{\mathcal}
\newcommand{\mi}{\mathit}
\newcommand{\mf}{\mathbf}
\newcommand{\mb}{\mathbb}
\renewcommand{\L}{\mc{L}}
\newcommand{\hd}{\hat{\delta}}

\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figures/}{#1.pdf_tex}
}
\pdfsuppresswarningpagegroup=1

\title{\textbf{COL380 Assignment 1 Report}}
\date{}

\begin{document}
\maketitle
\tableofcontents

\section{Description of programs}

\subsection{Serial program}

The serial program is almost the same as the simple version that was given to us.

\subsection{Parallel version 1}

In this version, we give a local variable representing the partial sum of some subset of iterations to each thread, which is then added to the sum in the end using a critical section, which will
be potentially run 8 times.

\subsection{Parallel version 2}

Suppose $T$ is the number of threads. In this version, we run the algorithm for $1 + \lceil \log_2 T \rceil$ steps. In the first step, which is the computationally most heavy step, we run a parallel for loop which has a local
variable for each thread that stores the sum of elements accessed in the iterations assigned to that thread. We use $O(T)$ extra memory to store these results. Then in the next $\lceil
\log_2 T \rceil$ iterations, we accumulate the partial sums of chunks of contiguously numbered threads in chunks of powers of two.

\subsection{Parallel version 3}

This version is quite similar to the previous version, but here we do static assignment of chunks for each thread using thread numbers and distributing the load somewhat equally.

\section{Total time taken by programs}

\subsection{Serial program}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        Time taken (in ms) & 0.010 & 0.875 & 77.191 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 1}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.101 & 0.945 & 74.458 \\
        \hline
        4  & 0.181 & 0.897 & 65.951 \\
        \hline
        8  & 0.328 & 0.900 & 65.885 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 2}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.140 & 0.787 & 65.378 \\
        \hline
        4  & 0.174 & 0.796 & 58.019 \\
        \hline
        8  & 0.324 & 0.930 & 56.788 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 3}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.084 & 0.810 & 68.155 \\
        \hline
        4  & 0.170 & 0.811 & 59.482 \\
        \hline
        8  & 0.333 & 1.141 & 65.414 \\
        \hline
    \end{tabular}
\end{center}

\section{Time taken by the parallelizable part of the programs}

\subsection{Serial program}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        Time taken (in ms) & 0.004 & 0.364 & 26.402 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 1}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.096 & 0.278 & 16.601 \\
        \hline
        4  & 0.176 & 0.301 & 10.489 \\
        \hline
        8  & 0.322 & 0.408 & 9.514 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 2}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.134 & 0.257 & 14.520 \\
        \hline
        4  & 0.168 & 0.271 & 10.647 \\
        \hline
        8  & 0.174 & 0.406 & 8.590 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 3}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2  & 0.079 & 0.278 & 16.137 \\
        \hline
        4  & 0.170 & 0.286 & 11.957 \\
        \hline
        8  & 0.333 & 0.492 & 14.040 \\
        \hline
    \end{tabular}
\end{center}

\section{Speedup, Efficiency, and Amdahl's law calculations}

We compute the fraction $f$ used in the statement of Amdahl's law for each value of $N$ using the serial program.

\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
    $N$ & $10^3$ & $10^5$ & $10^7$ \\
    \hline
    $f$ & 0.4 & 0.416 & 0.342 \\
    \hline
\end{tabular}
\end{center}

Using Amdahl's law, if the maximum possible speedup is $s$, and the number of processors is $p$ (equal to the number of threads for this assignment, since the number of threads is small and less than the number of
processors on my machine), then

\[
    s = \frac{1}{\left(1 - f\right) + \frac{f}{p}}
\]
The ideal speedups would then be
\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 1.25 & 1.26 & 1.21 \\
        \hline
        4 & 1.43 & 1.45 & 1.34 \\
        \hline
        8 & 1.54 & 1.57 & 1.43 \\
        \hline
    \end{tabular}
\end{center}

For the real speedups, the tables are as follows:

\subsection{Parallel version 1}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.099 & 0.926 & 1.037 \\
        \hline
        4 & 0.055 & 0.975 & 1.170 \\
        \hline
        8 & 0.030 & 0.972 & 1.171 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 2}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.071 & 1.112 & 1.181 \\
        \hline
        4 & 0.057 & 1.099 & 1.313 \\
        \hline
        8 & 0.031 & 0.941 & 1.359 \\
        \hline
    \end{tabular}
\end{center}


\subsection{Parallel version 3}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.119 & 1.080 & 1.132 \\
        \hline
        4 & 0.059 & 1.079 & 1.298 \\
        \hline
        8 & 0.031 & 0.767 & 1.180 \\
        \hline
    \end{tabular}
\end{center}

As far as the efficiency is concerned, it is given by

\[
    e = \frac{s}{p}
\]

So the efficiencies are as tabulated below:

\subsection{Parallel version 1}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.049 & 0.463 & 0.518 \\
        \hline
        4 & 0.014 & 0.244 & 0.293 \\
        \hline
        8 & 0.004 & 0.122 & 0.146 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 2}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.035 & 0.556 & 0.590 \\
        \hline
        4 & 0.014 & 0.275 & 0.428 \\
        \hline
        8 & 0.004 & 0.117 & 0.170 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Parallel version 3}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Number of threads, $N$ & $10^3$ & $10^5$ & $10^7$ \\
        \hline
        2 & 0.056 & 0.540 & 0.566 \\
        \hline
        4 & 0.030 & 0.270 & 0.325 \\
        \hline
        8 & 0.004 & 0.096 & 0.147 \\
        \hline
    \end{tabular}
\end{center}


\section{Analysis}

We can observe the following things:

\begin{enumerate}
    \item Amdahl's law is never followed accurately if it is interpreted to give an estimate of the real speedup, but if it is interpreted as a theoretical upper-bound, then yes, it is followed.
        It is still quite imprecise in terms of predicting the correct speedup, but as $N$ increases, we get a better and better approximation (due to overhead being less significant than the
        actual computation).
    \item When the data size is small, the main bottleneck in the program is the overhead associated with threads, including context switches, waiting and so on. For moderate data sizes,
        this is still a bottleneck, but not so prominent. The usage of threads shines when the data is large (i.e., when $N = 10^7$), giving us good speedups, somewhat close to the ideal speedups
        as well. This can be further verified from the time taken by the parallelizable part of the programs for each version.
    \item The second version is more efficient than the first version. This is because in the first version, the critical section is run by $T$ threads, and hence requires more time (since any code
        run on it would in a way run sequentially, while in the second version, there is no critical section, but $\lceil \log_2 T \rceil$ iterations where the threads all run in parallel,
        so it runs faster.
    \item The second version and the third version work at similar speeds, except for the cases where $N = 10^3$, and the case where there are 8 threads. In the first case, the effect of dynamic
        scheduling overhead is clearly visible, and in the second case, it seems like there is some anomaly. Also, by explicitly carrying out a
        comparison with static and dynamic scheduling provided by OpenMP, there was a similar trend there too.
\end{enumerate}

% \section{Running the code}
% 
% The code is in the files \texttt{sum.c} (for the serial code), and \texttt{sumX.c} where \texttt{X} is the version of the parallel code.\nl
% To create an executable \texttt{e} from file \texttt{e.c}, run \texttt{make e}.\nl
% To run the serial code, run \texttt{make 0}.\nl
% To run version \texttt{X} of the parallel code, run \texttt{make X}.\nl
% To clean up any executable files in the directory, run \texttt{make} or \texttt{make clean}.


\end{document}
